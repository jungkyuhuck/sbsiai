import openai
import numpy as np
import faiss
import pickle
import kss
from pymongo import MongoClient
import os
import time

# âœ… OpenAI API í‚¤ ì„¤ì •
openai.api_key = ""

# âœ… ì„ë² ë”© ìƒì„± í•¨ìˆ˜
def get_embedding(text: str) -> list:
    try:
        response = openai.Embedding.create(
            input=text,
            model="text-embedding-ada-002"
        )
        return response["data"][0]["embedding"]
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ì‹¤íŒ¨: {text[:30]}... â†’ {e}")
        return None

# âœ… MongoDBì—ì„œ ë°ì´í„° ì¶”ì¶œ ë° í…ìŠ¤íŠ¸ ë¶„í•´
def fetch_episodes_and_characters(mongo_uri: str, db_name: str, collection_name: str) -> list:
    client = MongoClient(mongo_uri)
    db = client[db_name]
    collection = db[collection_name]

    cursor = collection.find({})
    all_texts = []

    for doc in cursor:
        program_title = doc.get("title") or doc.get("program_title") or "UNKNOWN"
        season = doc.get("season", 0)

        # ğŸ“º episodes ì²˜ë¦¬
        episodes = doc.get("episodes", [])
        for ep in episodes:
            ep_no = ep.get("episode", "UNKNOWN")

            # 1) summary
            summary = ep.get("summary", "").strip()
            if summary:
                sentences = kss.split_sentences(summary)
                for sent in sentences:
                    all_texts.append(f"[{program_title} S{season}E{ep_no}] ì¤„ê±°ë¦¬: {sent.strip()}")

            # 2) vtt
            vtt = ep.get("vtt", "").strip()
            if vtt:
                vtt_sentences = kss.split_sentences(vtt)
                print(f"\nğŸ¬ [DEBUG] {program_title} S{season}E{ep_no} - ëŒ€ì‚¬ ë¬¸ì¥ ìˆ˜: {len(vtt_sentences)}")
                for i, sent in enumerate(vtt_sentences):
                    preview = sent.strip()[:60].replace("\n", " ")
                    print(f"  ğŸ”¹ ({i + 1}) {preview}...")
                    all_texts.append(f"[{program_title} S{season}E{ep_no}] ëŒ€ì‚¬: {sent.strip()}")

        # ğŸ‘¤ characters ì²˜ë¦¬
        characters = doc.get("characters", [])
        for ch in characters:
            name = ch.get("name", "UNKNOWN")
            description = ch.get("description", "").strip()
            if description:
                sentences = kss.split_sentences(description)
                for sent in sentences:
                    all_texts.append(f"[{program_title} ìºë¦­í„° {name}] ì„¤ëª…: {sent.strip()}")

    return all_texts

# âœ… FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥
def build_and_save_index(texts: list,
                         faiss_path: str = "C:/Users/apf_temp_admin/PycharmProjects/newai/sbs_index.faiss",
                         meta_path: str = "C:/Users/apf_temp_admin/PycharmProjects/newai/sbs_metadata.pkl"):
    vectors = []
    metadata = []
    seen = set()
    count_total = 0
    count_embedded = 0
    count_dialogue = 0

    # ë””ë ‰í† ë¦¬ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs(os.path.dirname(faiss_path), exist_ok=True)

    for text in texts:
        count_total += 1

        # ì¤‘ë³µ ì œê±°
        if text in seen:
            continue
        seen.add(text)

        # ëŒ€ì‚¬ ì—¬ë¶€ í™•ì¸
        if "ëŒ€ì‚¬:" in text:
            count_dialogue += 1

        # OpenAI ì„ë² ë”© ì‹œë„
        embedding = get_embedding(text)
        if embedding:
            vectors.append(embedding)
            metadata.append(text)
            count_embedded += 1
        else:
            print(f"âš ï¸ ì„ë² ë”© ì‹¤íŒ¨: {text[:40]}")

        time.sleep(0.1)

    # ë²¡í„° ì €ì¥
    if not vectors:
        print("âŒ ì €ì¥í•  ë²¡í„° ì—†ìŒ.")
        return

    np_vectors = np.array(vectors).astype("float32")
    dim = len(np_vectors[0])
    index = faiss.IndexFlatL2(dim)
    index.add(np_vectors)

    faiss.write_index(index, faiss_path)
    with open(meta_path, "wb") as f:
        pickle.dump(metadata, f)

    print("\nâœ… ìµœì¢… ì €ì¥ ì™„ë£Œ")
    print(f"ì´ ì²˜ë¦¬ í…ìŠ¤íŠ¸ ìˆ˜: {count_total}")
    print(f"ì„ë² ë”© ì„±ê³µ ìˆ˜: {count_embedded}")
    print(f"ëŒ€ì‚¬ ë¬¸ì¥ í¬í•¨ ìˆ˜: {count_dialogue}")
    print(f"ìµœì¢… ì €ì¥ëœ ë©”íƒ€ë°ì´í„° ìˆ˜: {len(metadata)}")

# âœ… ì‹¤í–‰
if __name__ == "__main__":
    MONGO_URI = "mongodb://43.201.154.108:27017"
    DB_NAME = "aiproject"
    COLLECTION_NAME = "deep learning_data"

    texts = fetch_episodes_and_characters(MONGO_URI, DB_NAME, COLLECTION_NAME)
    build_and_save_index(texts)
